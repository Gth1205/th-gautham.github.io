---
title: "Pipelines"
date: 2020-07-23
tags: [pipeline, data science, machine learning system, tidbit]
toc: true
toc_sticky: true
header:
  image: "/images/mountain-image-3.jpg"
  caption: "Photo credit: [**Unsplash.com**](https://unsplash.com)"
excerpt: "A sequence of data processing components in a Machine learning system"
---


Pipelines are a very common term used in setting up a machine learning systems. 
They consist of components that run asynchronously. Each component pulls in a large amount 
of data, processes it, and spits out the result in another data store.
Then, some time later, the next component in the pipeline
pulls this data and spits out its own output.

Each component is fairly self-contained: the interface between 
components is simply the data store. This makes the system simple 
to grasp (with the help of a data flow graph), and different teams can focus on 
different components. Moreover, if a component breaks down, the downstream components can 
often continue to run normally using the last output. This makes the architecture quite robust.

A drawback is, when a component breaksdown and goes unnoticed for some time if
monitoring is not implemented. 